# OfficeGPT Project Flow ğŸ”„

## File Responsibilities

### **What Happened to Old Files?**

| Old File  | What It Did                     | Now Handled By                       |
| --------- | ------------------------------- | ------------------------------------ |
| `chat.js` | CLI chat interface for terminal | `server.js` â†’ `/api/chat` endpoint   |
| `rag.js`  | Test file to index documents    | `server.js` â†’ `/api/upload` endpoint |

---

## Current Project Flow

### ğŸ“ **Core Files (3 files only!)**

```
server.js    â†’ Web server + API endpoints (handles upload & chat)
prepare.js   â†’ PDF processing + embeddings (called by server.js)
public/      â†’ Frontend UI (HTML/CSS/JS)
```

---

## ğŸ”„ Complete Application Flow

### **PHASE 1: User Uploads PDF**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER ACTION (Frontend)                                  â”‚
â”‚    File: public/index.html + public/script.js              â”‚
â”‚    - User drags & drops PDF or clicks upload              â”‚
â”‚    - JavaScript creates FormData with PDF file            â”‚
â”‚    - Sends POST request to /api/upload                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. SERVER RECEIVES REQUEST (Backend)                       â”‚
â”‚    File: server.js (Line 60-88)                           â”‚
â”‚                                                            â”‚
â”‚    app.post('/api/upload', upload.single('pdf'), ...)     â”‚
â”‚    - Multer saves PDF to uploads/ folder                  â”‚
â”‚    - Gets file path                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CALL INDEXING FUNCTION                                  â”‚
â”‚    File: server.js â†’ prepare.js                           â”‚
â”‚                                                            â”‚
â”‚    await indexTheDocument(filePath)                        â”‚
â”‚    - Calls function from prepare.js                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. PROCESS PDF (prepare.js)                               â”‚
â”‚    File: prepare.js (Line 24-90)                          â”‚
â”‚                                                            â”‚
â”‚    a) Load PDF with PDFLoader                             â”‚
â”‚    b) Split into 500-char chunks (RecursiveTextSplitter) â”‚
â”‚    c) Generate embeddings (Google Gemini)                 â”‚
â”‚    d) Convert embeddings to arrays                         â”‚
â”‚    e) Upload to Pinecone vector database                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. CLEANUP & RESPONSE (server.js)                         â”‚
â”‚    File: server.js (Line 73-76)                           â”‚
â”‚                                                            â”‚
â”‚    - Delete local PDF file (no longer needed)             â”‚
â”‚    - Send success response to frontend                     â”‚
â”‚    - Frontend shows success message                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **PHASE 2: User Asks Question**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER TYPES QUESTION (Frontend)                         â”‚
â”‚    File: public/script.js (Line 94-102)                   â”‚
â”‚    - User types: "How many sick leaves do I get?"         â”‚
â”‚    - JavaScript sends POST to /api/chat                    â”‚
â”‚    - Body: { message: "How many sick leaves..." }         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. SERVER RECEIVES CHAT REQUEST                           â”‚
â”‚    File: server.js (Line 92-150)                          â”‚
â”‚                                                            â”‚
â”‚    app.post('/api/chat', async (req, res) => {...})       â”‚
â”‚    - Gets user question from request body                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. SEARCH VECTOR DATABASE                                 â”‚
â”‚    File: server.js (Line 104-105)                         â”‚
â”‚    Uses: prepare.js â†’ vectorStore (exported)              â”‚
â”‚                                                            â”‚
â”‚    const chunks = await vectorStore.similaritySearch(     â”‚
â”‚        question, 3                                         â”‚
â”‚    )                                                       â”‚
â”‚    - Converts question to embedding                        â”‚
â”‚    - Finds 3 most similar chunks in Pinecone              â”‚
â”‚    - Returns relevant text chunks                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. PREPARE CONTEXT FOR AI                                 â”‚
â”‚    File: server.js (Line 106-124)                         â”‚
â”‚                                                            â”‚
â”‚    - Combines 3 chunks into single context string        â”‚
â”‚    - Creates system prompt for AI                         â”‚
â”‚    - Adds user question + context                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. SEND TO GROQ AI                                        â”‚
â”‚    File: server.js (Line 126-141)                         â”‚
â”‚                                                            â”‚
â”‚    const completion = await groq.chat.completions.create({ â”‚
â”‚        model: 'llama-3.3-70b-versatile',                  â”‚
â”‚        messages: [system_prompt, user_query]              â”‚
â”‚    })                                                      â”‚
â”‚    - AI reads context and generates answer                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. RETURN ANSWER TO USER                                  â”‚
â”‚    File: server.js â†’ public/script.js                     â”‚
â”‚                                                            â”‚
â”‚    - Server sends JSON: { response: "You get 6..." }     â”‚
â”‚    - Frontend displays in chat bubble                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Detailed File Breakdown

### **1. server.js** (Main Controller)

```javascript
// OLD: chat.js did CLI chat â†’ NOW: /api/chat endpoint does web chat
// OLD: rag.js did indexing â†’ NOW: /api/upload endpoint does indexing

Lines 1-19:   Import dependencies
Lines 20-50:  Setup Express, Multer, uploads folder
Lines 51-58:  Initialize Groq AI client

Lines 60-88:  POST /api/upload
              â”œâ”€â”€ Receive PDF file
              â”œâ”€â”€ Call prepare.js â†’ indexTheDocument()
              â”œâ”€â”€ Delete local PDF
              â””â”€â”€ Return success

Lines 90-150: POST /api/chat
              â”œâ”€â”€ Receive user question
              â”œâ”€â”€ Search vectorStore (from prepare.js)
              â”œâ”€â”€ Get relevant chunks
              â”œâ”€â”€ Send to Groq AI
              â””â”€â”€ Return answer

Lines 152-157: Health check endpoint
Lines 159-162: Start server on port 3000
```

### **2. prepare.js** (PDF Processor)

```javascript
// Called by server.js for both upload and chat

Lines 1-6:    Import libraries (PDF, Gemini, Pinecone)
Lines 8-10:   Initialize Google Gemini embeddings
Lines 12-16:  Initialize Pinecone client
Lines 18-22:  Create vectorStore (exported to server.js)

Lines 24-90:  indexTheDocument(filePath)
              â”œâ”€â”€ Load PDF file
              â”œâ”€â”€ Split into chunks
              â”œâ”€â”€ Generate embeddings (Gemini)
              â”œâ”€â”€ Convert to arrays
              â”œâ”€â”€ Flatten metadata
              â””â”€â”€ Upload to Pinecone

EXPORTS:
- vectorStore â†’ Used by server.js for searching
- indexTheDocument() â†’ Called by server.js /api/upload
```

### **3. public/script.js** (Frontend)

```javascript
// Handles all user interactions

Lines 1-6:    API URL configuration
Lines 8-13:   Get DOM elements
Lines 15-32:  Drag & drop handlers
Lines 34-65:  handleFileUpload()
              â””â”€â”€ Sends PDF to /api/upload

Lines 67-78:  showUploadStatus()
Lines 80-92:  Enter key listener

Lines 94-146: sendMessage()
              â”œâ”€â”€ Send question to /api/chat
              â”œâ”€â”€ Show loading animation
              â”œâ”€â”€ Display AI response
              â””â”€â”€ Handle errors

Lines 148-165: addMessage() - Add chat bubbles
Lines 167-171: removeMessage() - Remove loading
Lines 173-177: Auto-resize textarea
```

---

## ğŸ”„ Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OfficeGPT System                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

UPLOAD FLOW:
User Browser â†’ public/script.js â†’ server.js â†’ prepare.js â†’ Gemini API
                                       â†“
                                  Pinecone DB â† Delete local PDF

CHAT FLOW:
User Browser â†’ public/script.js â†’ server.js â†’ prepare.js (vectorStore)
                                       â†“           â†“
                                   Pinecone â† Search similar chunks
                                       â†“
                                   Groq AI â† Question + Context
                                       â†“
                                   Response â†’ User Browser
```

---

## ğŸ¯ Key Changes from Old Structure

### Before (3 separate files):

```
chat.js     â†’ Terminal-based chat (CLI)
rag.js      â†’ Test script to index one PDF
prepare.js  â†’ PDF processing functions
```

### After (Integrated into server.js):

```
server.js   â†’ Web server with:
              - /api/upload (replaced rag.js)
              - /api/chat (replaced chat.js)
              - Uses prepare.js functions

prepare.js  â†’ Same functions, now called by server.js
public/     â†’ Web UI instead of CLI
```

---

## ğŸ”§ How Each Component Works

### **Multer (File Upload)**

```javascript
// In server.js
const storage = multer.diskStorage({
  destination: "uploads/",
  filename: "document-<timestamp>.pdf",
});
```

- Temporarily saves PDF to disk
- Provides file path to processing function
- File deleted after processing

### **Vector Store (Persistent Memory)**

```javascript
// In prepare.js
export const vectorStore = await PineconeStore.fromExistingIndex(embeddings, {
  pineconeIndex,
});
```

- Connects to Pinecone cloud database
- Exported for use in server.js
- Used for similarity search during chat

### **Embeddings (Text â†’ Numbers)**

```javascript
// In prepare.js
const embeddings = new GoogleGenerativeAIEmbeddings({
  model: "text-embedding-004",
});
```

- Converts text to 768-dimensional vectors
- Used for both indexing and searching
- Free tier from Google

### **LLM (Answer Generation)**

```javascript
// In server.js
const completion = await groq.chat.completions.create({
  model: "llama-3.3-70b-versatile",
  messages: [systemPrompt, userQuery],
});
```

- Takes context + question
- Generates natural language answer
- Fast and free through Groq

---

## ğŸ“Š API Endpoints Summary

| Endpoint      | Method | Purpose             | Called By  |
| ------------- | ------ | ------------------- | ---------- |
| `/`           | GET    | Serve HTML page     | Browser    |
| `/api/upload` | POST   | Upload & index PDF  | Frontend   |
| `/api/chat`   | POST   | Answer questions    | Frontend   |
| `/api/health` | GET    | Check server status | Monitoring |

---

## ğŸš€ Execution Order

### **Server Startup:**

```
1. server.js runs
   â†“
2. Imports prepare.js
   â†“
3. prepare.js initializes:
   - Gemini embeddings
   - Pinecone connection
   - Creates vectorStore
   â†“
4. Server starts on port 3000
   â†“
5. Ready to receive requests!
```

### **User Upload:**

```
1. User selects PDF
   â†“
2. Frontend sends to /api/upload
   â†“
3. server.js receives file
   â†“
4. Calls prepare.js â†’ indexTheDocument()
   â†“
5. PDF processed and stored in Pinecone
   â†“
6. Local file deleted
   â†“
7. Success message to user
```

### **User Chat:**

```
1. User types question
   â†“
2. Frontend sends to /api/chat
   â†“
3. server.js searches vectorStore
   â†“
4. Gets 3 relevant chunks
   â†“
5. Sends to Groq AI with context
   â†“
6. AI generates answer
   â†“
7. Answer displayed to user
```

---

## ğŸ’¡ Why This Structure?

**Benefits:**

- âœ… **Single server file** - Easy to deploy
- âœ… **Web interface** - Better UX than CLI
- âœ… **Separated concerns** - prepare.js only handles PDF processing
- âœ… **Reusable functions** - prepare.js exports for server.js
- âœ… **RESTful API** - Standard web architecture
- âœ… **No redundancy** - No need for separate test files

**The old structure:**

- âŒ chat.js only worked in terminal
- âŒ rag.js was just a test file
- âŒ Couldn't serve web interface

**The new structure:**

- âœ… Everything accessible via web browser
- âœ… One unified server handling all requests
- âœ… Professional API structure
- âœ… Production-ready

---

Made with â¤ï¸ - Now you understand the complete flow!
